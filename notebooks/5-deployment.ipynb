{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM PROJECT - Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I was going to actually deploy this model, I would probably use Streamlit, as it is more robust than Flask, and those are the only two options that I know of. I had a lot of trouble getting the predictions out of my model, however, and needed ChatGPT to help me, so there would need to be a lot of work before that could happen. <p>\n",
    "\n",
    "In terms of ethical considerations:<ul>\n",
    "- I did not inventory the data, so it is possible there is harmful or offensive content in it that might not be desirable for use in classifying new material<p>\n",
    "- if this model were to be fed into a recommender system as is, and it is left completely failing to return an entire category, (which I know corresponds to alt.atheism), that demonstrates a bias of some kind at worst and a failure to reach an audience at best<p>\n",
    "- depending on the way it is deployed, the model could be configured so that new documents are entered into it for classification and then onces sharing the same category and similar words are returned, and grow its catalogue that way, in which case there would need to be guardrails to watch for the addition of unwanted content, as well as duplicates"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
